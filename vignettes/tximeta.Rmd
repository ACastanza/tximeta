---
title: "tximeta: Import transcript quantification with automagic generation of metadata"
author: "Michael Love, Rob Patro"
date: "`r format(Sys.time(), '%m/%d/%Y')`"
output: 
  html_document:
    highlight: tango
abstract: >
  `tximeta` performs numerous annotation and metadata gathering tasks on
  behalf of users during the import of transcript quantifications from
  *Salmon* or *Sailfish* into R/Bioconductor. Transcript ranges and
  metadata are added automatically, facilitating combining multiple
  genomic datasets and helping to prevent bioinformatic errors.
---

```{r echo=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

# Analysis starts with sample table

The first step using `tximeta` is to read in the sample table, which
will become the *column data*, `colData`, of the final object,
a *SummarizedExperiment*. The sample table should contain all the
information we need to identify the *Salmon* quantification
directories. Here we will use a *Salmon* quantification file in the
*tximportData* package to demonstrate the usage of `tximeta`. We do
not have a sample table, so we construct one in R. It is recommended
to keep a sample table as a CSV or TSV file while working on an
RNA-seq project with multiple samples.

```{r}
dir <- system.file("extdata/salmon_dm", package="tximportData")
# here gzipped, normally these are not
files <- file.path(dir, "SRR1197474_cdna", "quant.sf.gz") 
file.exists(files)
coldata <- data.frame(files, names="SRR1197474", condition="A", stringsAsFactors=FALSE)
coldata
```

`tximeta` expects at least two columns in `coldata`: 

1. `files` - a pointer to the `quant.sf` files
2. `names` - the unique names that should be used to identify samples

# Running tximeta from a sample table

Normally, we would just run `tximeta` like so:

```{r eval=FALSE}
library(tximeta)
se <- tximeta(coldata)
```

However, to avoid downloading remote GTF files during this vignette, we
will point to a GTF file saved locally (in the *tximportData*
package). We link the transcriptome of the *Salmon* index to its
locally saved GTF. This following code is therefore not recommended
for a typically workflow, but is particular to the vignette code.

```{r}
dir <- system.file("extdata", package="tximeta")
indexDir <- file.path(dir, "Drosophila_melanogaster.BDGP6.cdna.v92_salmon_0.10.2")
fastaFTP <- "ftp://ftp.ensembl.org/pub/release-92/fasta/drosophila_melanogaster/cdna/Drosophila_melanogaster.BDGP6.cdna.all.fa.gz"
dir2 <- system.file("extdata/salmon_dm", package="tximportData")
gtfPath <- file.path(dir2,"Drosophila_melanogaster.BDGP6.92.gtf.gz")
makeLinkedTxome(indexDir=indexDir,
                source="Ensembl",
                organism="Drosophila melanogaster",
                version="92",
                genome="BDGP6",
                fasta=fastaFTP,
                gtf=gtfPath,
                write=FALSE)
```

```{r}
library(tximeta)
se <- tximeta(coldata)
```

# What happened? 

`tximeta` recognized the signature of the transcriptome that the files
were quantified against, it accessed the GTF file of the transcriptome
source, found and attached the transcript ranges, and added the
appropriate transcriptome and genome metadata.  A remote GTF is only
downloaded once, and a local or remote GTF is only computed into a
*TxDb* once: if `tximeta` recognizes that it has seen this index
before, it will simply use a cached version of the transcript
metadata and ranges.

Note the warning that 9 of the transcripts are missing from the GTF
file and so are dropped from the final output.

We plan to create and maintain a large table of signatures for as many
sources, organisms, versions of transcriptomes as possible. We are
also developing support for *linked transcriptomes*, where one or
more sources for transcript sequences have been combined or
filtered. See the `linkedTxome` vignette in this package for a
demonstration. (The *makeLinkedTxome* function was used above to avoid
downloading the GTF during the vignette building process.)

# Examining SummarizedExperiment output

We, of course, have our coldata from before. Note that we've removed `files`.

```{r}
colData(se)
```

Here we show the three matrices that were imported. (Note: this part
would need updating for un-reduced inferential variance matrices.) 
(Second note: the downstream packages would need updating of their
functions or workflows, e.g. `DESeqDataSetFromTximport` needs a little
update to work with these *SummarizedExperiments* instead of simple lists.)

```{r}
assayNames(se)
```

Thanks to `tximeta` we have automagically imported the correct ranges
for the transcripts. 

```{r}
rowRanges(se)
```

We have appropriate genome information, which prevents us from making 
bioinformatic mistakes:

```{r}
seqinfo(se)
```

# Easy summarization to gene-level

Because the SummarizedExperiment maintains all the metadata of its
creation, it also keeps a pointer to the necessary database for
summarizing transcript-level quantifications and bias corrections to
the gene-level. If necessary, `summarizeToGene` can pull down the
remote source for summarization, but given that we've already built a
TxDb once, it simply loads the stashed version.

```{r}
gse <- summarizeToGene(se)
rowRanges(gse)
```

# Add different identifiers

We would like to add support to easily map transcript or gene
identifiers from one annotation to another. This is just a prototype
function, but we show how we can easily add alternate IDs given that we
know the organism and the source of the transcriptome. (This function
currently only works for Gencode and Ensembl gene or transcript IDs
but could be extended to work for arbitrary sources.)

```{r}
library(org.Dm.eg.db)
gse <- addIds(gse, "SYMBOL", gene=TRUE)
mcols(gse)[1:10,]
```

# Run a differential expression analysis

The following code chunk demonstrates how to build a *DESeqDataSet*
and begin a differential expression analysis. Likely we would
simplify these steps with a convenience function either in *tximeta*
or in *DESeq2*.

```{r}
suppressPackageStartupMessages(library(DESeq2))
gse2 <- gse
assayNames(gse2)
# rounding counts
assay(gse2) <- round(assay(gse2))
# rename the "length" assay to "avgTxLength"
# DESeq2 will then use this matrix for calculating bias offsets
assayNames(gse2)[3] <- "avgTxLength"
# make a DESeqDataSet, here there is no factor
# to divide the samples so we use ~1
dds <- DESeqDataSet(gse2, ~1)
dds <- estimateSizeFactors(dds)
# ... and so on
```

# Find nearest transcripts to a ChIP-seq peak

Suppose we want to find overlap of the expression with binding sites
of a transcription factor:

```{r}
library(AnnotationHub)
ah <- AnnotationHub()
chip <- query(ah, c("GM12878", "MEF2A", "narrowPeak"))[[1]]
```

First try, let's find the nearest transcript to a given ChIP-seq peak:

```{r error=TRUE}
nearest(chip[1], se)
```

We get an <font color="red"><b>ERROR</b></font>: all chromosomes have
incompatibile genomes! Good! 
The point of `tximeta` is to reduce these kind of simple bioinformatic
mistakes that can add weeks or months of dead-end results to large
genomics projects. 
We can use liftover chains to get us going in the right direction,
comparing hg38 to hg38 (this code chunk un-evaluated).

```{r eval=FALSE}
url <- "http://hgdownload.cse.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz"
file <- "hg19ToHg38.over.chain.gz"
if (!file.exists(file)) download.file(url, file, method="wget")
system(paste("gunzip ",file))
```

```{r}
chainfile <- system.file("extdata/hg19ToHg38.over.chain", package="tximeta")
```

We move our ChIP-seq data to hg38:

```{r}
chip.lift <- liftOverHelper(chip, chainfile=chainfile, to="hg38")
```

Now we can find the nearest transcript to a given ChIP-seq peak:

```{r}
nearest(chip.lift[1], se)
assay(se)[nearest(chip.lift[1], se),,drop=FALSE]
```

Or we can take a slice of the transcriptome data that is within 10 kb
of a given ChIP-seq peak:

```{r}
# which rows of SE in this window?
which(overlapsAny(se, chip.lift[1] + 1e4))
```

Perhaps even more exciting, we can now automate functional annotation of
transcriptome data using Bioconductor's annotation suite.

# Metadata galore

```{r}
names(metadata(se))
str(metadata(se)$quantInfo)
str(metadata(se)$txomeInfo)
str(metadata(se)$tximetaInfo)
str(metadata(se)$txdbInfo)
```

# Next steps

### Basic functionality

* Switching `rowRanges` from transcript ranges to exons-by-transcript
  ranges list, or from gene ranges to exons-by-gene ranges list.
* As is already supported in the `tximport` release, also import inferential
  variance matrices (Gibbs samples or bootstrap samples)

### Facilitate plots and summaries
    
* Basic plots across samples: abundances, mapping rates, rich bias model parameters
* Time summaries: when quantified? when imported? I would love to
  know when the library was prepared and sequenced but this seems hopeless.

### Challenges

* Building out actual, sustainable plan for supporting as many
  organisms and sources as possible. We can define rules which
  determine where the FASTA and GTF files will be based on `source` and
  `version` (also here I ignored something like "type", e.g. CHR
  or ALL gene files from Gencode)
* Some support already for linked transcriptomes, see `linkedTxomes`
  vignette. Need to work more on combining multiple sources
  (potentially meta-transcriptomes from different organisms?), and
  also on how to approach de novo transcriptomes, and how to support
  reproducibility there.
* Facilitate functional annotation, either with vignettes/workflow or
  with additional functionality. E.g.: 
  housekeeping genes, arbitrary gene sets, genes expressed in GTEx tissues
* `liftOver` is clunky and doesn't integrate with
  *GenomeInfoDb*. It requires user input and there's a chance to
  mis-annotate. Ideally this should all be automated.

# Session info

```{r}
library(devtools)
session_info()
```
